[["ausentismo-laboral.html", "Análisis de series temporales: Ausentismo laboral Capítulo 1 AUSENTISMO LABORAL 1.1 Introducción 1.2 Finalidad del estudio 1.3 Diseño del estudio", " Análisis de series temporales: Ausentismo laboral Ricardo Ortiz; Jaime Martinez, Jeisson Rodriguez 2025-06-08 Capítulo 1 AUSENTISMO LABORAL 1.1 Introducción El ausentismo es definido como la ausencia de un empleado en su ambiente laboral con justificación o sin ella [1]. Cuando esto ocurre en una compañía se puede generar un aumento de costos (horas extra) en otros empleados llevando a sobrecarga o desmotivacion [2]. Las causas pueden ser múltiples, desde enfermedades, problemas económicos, razones personales, falta de interés, entre otras [3] En EE. UU. menos de la mitad de las compañías tiene un sistema de rastreo de ausentismo y solo un 16% implementan medidas para reducirlo [4], por esta razón este evento tiene un impacto significativo en el desarrollo financiero de las empresas teniendo un fuerte impacto en la estructura organizacional. 1.2 Finalidad del estudio El objetivo del análisis de este conjunto de datos es aplicar técnicas de series de tiempo para identificar el comportamiento del ausentismo a través de un periodo de tiempo; esto permitirá desarrrollar estrategias para maximizar la eficiencia operativa de la empresa al identificar los factores asociados al ausentismo laboral. 1.3 Diseño del estudio La base de datos a utilizar es Absenteeism at work es una base de acceso libre del UCI Machine Learning Repository cuyo dataset contiene información de julio de 2007 a julio de 2010 en una compañia en Brazil [5]. Los datos contienen 740 registros en 19 variables. Esta base de datos posee características que la hacen idónea para la investigación al poseer cobertura conceptual (la información corresponde a la finalidad del estudio), cobertura geográfica (Brazil), cobertura temporal (2007-2010) y amplitud porque en esta fuente de tipo secundario se obtendrá la información de las variables geográficas, demográficas y de otras variables relacionadas con el ausentismo. Conjunto de datos disponible en: https://archive.ics.uci.edu/dataset/445/absenteeism+at+work "],["análisis-de-los-datos.html", "Capítulo 2 Análisis de los datos 2.1 Media Movil 2.2 Rezagos 2.3 Análísis de estacionalidad 2.4 Descomposición de la serie temporal 2.5 Estacionariedad 2.6 Diferenciación 2.7 Conclusión", " Capítulo 2 Análisis de los datos En el presente análisis se examina el comportamiento del ausentismo laboral a partir del conjunto de datos “Absenteeism at Work” disponible en el repositorio de la UCI Machine Learning. Para identificar patrones temporales y tendencias generales, se implementan técnicas de suavizamiento como la aproximación mediante promedios móviles. Además, se exploran los rezagos (lags) para evaluar la influencia de valores pasados en la dinámica actual del ausentismo, buscando detectar posibles relaciones de dependencia temporal. Finalmente, se realiza un análisis de estacionalidad para determinar si existen variaciones sistemáticas asociadas a ciclos recurrentes, como días de la semana, meses o estaciones del año, que afecten la frecuencia del ausentismo. Estas aproximaciones permiten construir una base sólida para entender mejor el fenómeno y orientar futuros modelos predictivos o estrategias de intervención en el contexto laboral. A continuación se procede a cargar los datos de ausentismo laboral desde un archivo local disponibles en: https://archive.ics.uci.edu/dataset/445/absenteeism+at+work. Se imprime el encabezado para ver el contenido del dataset. # Cargar datos desde un archivo CSV datos &lt;- read.csv(&quot;/Users/ricardoortiz/Desktop/Maestria_CD/Series_Tiempo/bookdown-TS/Absenteeism_at_work.csv&quot;, sep = &quot;;&quot;) # Mostrar primeras filas con formato profesional knitr::kable( head(datos), format = &quot;html&quot;, caption = &quot;Tabla 1: Vista preliminar del ausentismo laboral&quot;, align = c(rep(&quot;l&quot;, 2), rep(&quot;c&quot;, ncol(datos)-2)), # Primeras 2 columnas a la izquierda col.names = gsub(&quot;_&quot;, &quot; &quot;, colnames(datos)) # Reemplazar _ por espacios ) %&gt;% kable_styling( bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;), full_width = FALSE, font_size = 13, position = &quot;center&quot; ) %&gt;% row_spec(0, bold = TRUE, color = &quot;white&quot;, background = &quot;#2c3e50&quot;) %&gt;% column_spec(1, width = &quot;8em&quot;) %&gt;% # Ancho fijo para primera columna column_spec(2, width = &quot;6em&quot;) %&gt;% footnote( general = &quot;Datos de absentismo laboral en una empresa&quot;, general_title = &quot;Fuente:&quot;, footnote_as_chunk = TRUE ) Table 2.1: Tabla 1: Vista preliminar del ausentismo laboral ID Reason.for.absence Month.of.absence Day.of.the.week Seasons Transportation.expense Distance.from.Residence.to.Work Service.time Age Work.load.Average.day Hit.target Disciplinary.failure Education Son Social.drinker Social.smoker Pet Weight Height Body.mass.index Absenteeism.time.in.hours 11 26 7 3 1 289 36 13 33 239.554 97 0 1 2 1 0 1 90 172 30 4 36 0 7 3 1 118 13 18 50 239.554 97 1 1 1 1 0 0 98 178 31 0 3 23 7 4 1 179 51 18 38 239.554 97 0 1 0 1 0 0 89 170 31 2 7 7 7 5 1 279 5 14 39 239.554 97 0 1 2 1 1 0 68 168 24 4 11 23 7 5 1 289 36 13 33 239.554 97 0 1 2 1 0 1 90 172 30 2 3 23 7 6 1 179 51 18 38 239.554 97 0 1 0 1 0 0 89 170 31 2 Fuente: Datos de absentismo laboral en una empresa Al revisar los datos se identifica que la variable de interés que puede ser apropiada para hacer el análisis es el tiempo de ausentismo en horas, ( Absenteeism.time.in.hours ). La cuál es la variable objetivo del dataset según la descripción del mismo. El dataset no incluye una fecha específica por lo que es necesario construirla a partir de variables tales como Month.of.absence y Day.of.the.weeek. Para ello, usamos el siguiente código. # Crear fechas de 2007 con día de la semana donde 1 = Domingo, ..., 7 = Sábado fechas_2007 &lt;- seq.Date(from = as.Date(&quot;2007-01-01&quot;), to = as.Date(&quot;2007-12-31&quot;), by = &quot;day&quot;) dias_semana_2007 &lt;- wday(fechas_2007, week_start = 7) # 1 = Domingo, 2 = Lunes, ..., 7 = Sábado dias_semana_2007_df &lt;- data.frame(Fecha = fechas_2007, Dia_de_la_semana = dias_semana_2007) # Crear la columna &#39;Fecha&#39; en el dataframe &#39;datos&#39; set.seed(123) datos &lt;- datos %&gt;% filter(!is.na(Month.of.absence) &amp; !is.na(Day.of.the.week)) %&gt;% mutate( Fecha = as.Date(sapply(1:nrow(.), function(i) { mes &lt;- Month.of.absence[i] dia_semana &lt;- Day.of.the.week[i] posibles_fechas &lt;- dias_semana_2007_df %&gt;% filter(month(Fecha) == mes &amp; Dia_de_la_semana == dia_semana) if (nrow(posibles_fechas) &gt; 0) { sample(posibles_fechas$Fecha, 1) } else { NA } }), origin = &quot;1970-01-01&quot;) ) # Verificar head(datos$Fecha) ## [1] &quot;2007-07-17&quot; &quot;2007-07-17&quot; &quot;2007-07-11&quot; &quot;2007-07-12&quot; &quot;2007-07-12&quot; ## [6] &quot;2007-07-20&quot; 2.1 Media Movil El ausentismo laboral día a día puede tener mucha variabilidad, pues algunos días hay cero horas y otros días hay ausencias largas. La media móvil reduce las fluctuaciones diarias y muestra una tendencia más limpia. En este caso se generó un gráfico que muestra en rojo la variabilidad real y en azul la media móvil. Se aplicó un promedio móvil de 5 días al ausentismo laboral registrado. A partir del gráfico se puede concluir que en el primer trimestre el ausentismo suele ser bajo a comparación de los siguientes trimestres, sobre todo el tercer que presenta un pico promedio de más de 50 horas 2.2 Rezagos El análisis de rezagos busca identificar si el ausentismo de hoy está relacionado con el ausentismo de días anteriores. Por ejemplo, interesa saber si un empleado que falta hoy tiene más probabilidad de faltar también mañana, o si, después de un día de alta ausencia, el ausentismo tiende a aumentar o disminuir en los días siguientes. Este tipo de relación temporal es fundamental para la construcción de modelos predictivos, como los modelos ARIMA o las regresiones que incorporan dependencias en el tiempo. ## [1] 0.04146078 ## [1] -0.008995374 ## [1] -0.001743892 El análisis de los rezagos a 1, 7 y 15 días muestra correlaciones muy bajas (0.041, - 0.008 y -0.0017 respectivamente), indicando la ausencia de dependencia temporal significativa en los datos de ausentismo laboral. Estos resultados sugieren que el ausentismo no sigue un patrón repetitivo ni está influenciado por ausencias anteriores, comportándose de manera aleatoria a lo largo del tiempo. Esto claramente está también influenciado por la forma como se construyó la serie de tiempo de forma aleatoria a partir de la información disponible. Este tipo de gráfico muestra la relación entre el valor en t y su valor en t-1, esto es: ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## `geom_smooth()` using formula = &#39;y ~ x&#39; En estos gráficos podemos observar que los puntos son caóticos o dispersos en todos los rezagos, no hay dependencia fuerte en el rezago, es decir no hay mucha relación entre el valor actual y el pasado. vamos a graficar la Autocorrelation Function (ACF), esto mide cuánta correlación existe entre la serie y sus propios rezagos. acf(datos$Absenteeism.time.in.hours, na.action = na.pass, main = &quot;ACF - Autocorrelación de ausencias&quot;) A partir del resultado del gráfico se interprta que no hay correlaciones significativas en los rezagos. 2.3 Análísis de estacionalidad La estacionalidad es un patrón repetitivo o cíclico que ocurre a intervalos regulares en una serie de tiempo, como cada semana, cada mes o cada año. En este caso, queremos ver si hay momentos del año (o del mes) en los que el ausentismo tiende a aumentar o disminuir sistemáticamente.Como en el conjunto de datos tenemos el mes (simulado con fechas) y las horas de ausentismo, podemos ver si ciertos meses muestran mayores ausencias que otros. El análisis de la estacionalidad mostró que el ausentismo laboral no presenta variaciones cíclicas fuertes a lo largo del año. Aunque se observan ligeras variaciones en algunos meses, no se identificaron patrones claros que indiquen un comportamiento estacional robusto. Esto sugiere que el ausentismo registrado responde más a factores puntuales que a eventos recurrentes en el tiempo, lo cual limita la capacidad predictiva basada en componentes estacionales. Sin embargo, al hacer el análisis semanal si parece observarse una tendencia de mayor ausentismo en los primeros días de la semana luego del fin de semana. Para abordar esta sección del documento sobre análisis de series temporales con base en el conjunto de datos de ausentismo laboral de la UCI, ahora se evalurán otros análisis como la descomposición, estacionariedad y si es necesario se aplicarán las transformaciones necesarias. 2.4 Descomposición de la serie temporal Cualqier serie se puede descomponer en su parte estacional, de tendencia y residual. Exiten dos alternativas, una descomposición por adición y multiplicativa. Para ello usaremos la función descompose. En un modelo aditivo, la serie temporal se descompone en: Tendencia (Trend): Refleja la dirección general del ausentismo a largo plazo (ej.: aumento o disminución progresiva). Estacionalidad (Seasonality): Patrones repetitivos cada año (ej.: picos en invierno por enfermedades o en festivos). Residuales (Residual): Variabilidad no explicada por los componentes anteriores (eventos aleatorios o errores). Para aplicar una descomposición con base en día de la semana, teniendo en cuenta la estructura del dataset y que se cuenta con datos para un año organizados por día del mes y día de la semana se siguen estos pasos. Se crea una serie temporal agregada por día de la semana y se asegura que haya varias semanas. # Agrupar por fecha y sumar las horas de ausencia (puede haber varias por día) serie_diaria &lt;- datos %&gt;% filter(!is.na(Fecha)) %&gt;% group_by(Fecha) %&gt;% summarise(Horas = sum(Absenteeism.time.in.hours, na.rm = TRUE)) %&gt;% arrange(Fecha) # Rellenar fechas faltantes (por si hay días sin datos) todas_las_fechas &lt;- data.frame( Fecha = seq.Date(min(serie_diaria$Fecha), max(serie_diaria$Fecha), by = &quot;day&quot;) ) serie_diaria &lt;- todas_las_fechas %&gt;% left_join(serie_diaria, by = &quot;Fecha&quot;) %&gt;% mutate(Horas = ifelse(is.na(Horas), 0, Horas)) Se usa ts() especificando frequency = 7 (para periodicidad semanal). # Crear la serie temporal con frecuencia semanal (7 días) ts_diaria &lt;- ts(serie_diaria$Horas, frequency = 7) Aplicar la función decompose() o stl() sobre la serie. Por ultimo se realiza el plot del gráfico. # Descomposición aditiva descomp &lt;- decompose(ts_diaria, type = &quot;additive&quot;) # Graficar resultado plot(descomp) A continuación se analizan los resultados obtenidos en el gráfico de descomposición de la serie temporal que representa, en el eje x, el índice temporal de observación, que en este caso es semanal (es decir, cada punto es una semana del año). El eje y representa el número total de horas de ausentismos laboral por semana que llegan a alcanzar hasta las 150 semanas, indicando semanas con alta acumulación de horas de ausencia. Observed (Observada): La serie original presenta variaciones notables, con múltiples picos que podrían corresponder a eventos puntuales de alto ausentismo. La serie muestra fluctuaciones regulares, lo que sugiere la presencia de estacionalidad y posiblemente una leve tendencia. Trend (Tendencia): La tendencia es irregular, pero revela periodos de aumento y disminución del ausentismo a lo largo del tiempo. Se observan tramos donde el nivel general de ausentismo se incrementa, seguidos de caídas, lo cual puede estar asociado a factores contextuales como estaciones del año que suelen estar asociadas con brotes de enfermedades o alergias. También puede mostrar tendencias asociadas a periodos frecuentes de ausentismo como semana santa, vacaciones de mitad y final de año. Seasonal (Estacionalidad): La componente estacional es clara y bien definida, con un patrón cíclico semanal o cercano al semanal (como fue el caso de la descomposición diaria por día de la semana). Esto sugiere que existe un patrón repetitivo y consistente en el ausentismo, posiblemente relacionado con los días laborales o fines de semana, en los que los niveles de ausentismo tienden a variar sistemáticamente. Random (Ruido aleatorio): El componente aleatorio muestra picos aislados, lo que indica eventos impredecibles que no pueden explicarse ni por la tendencia ni por la estacionalidad. Estos podrían deberse a causas extraordinarias o a la presencia de variables de confusión. 2.5 Estacionariedad Establece la estabilidad de la media y la covarianza en la serie de tiempo. Diferente a la estacionalidad en la que se observa el periodo o frecuencia en el que se repite la serie. Para ello primero procedemos a hacer una visualización de la serie para ver si hay tendencias. serie_diaria %&gt;% ggplot(aes(x = Fecha, y = Horas)) + geom_line(color = &quot;steelblue&quot;) + labs(title = &quot;Serie temporal de horas de ausentismo&quot;, x = &quot;Fecha&quot;, y = &quot;Horas de Ausencia&quot;) + theme_minimal() Luego aplicamos la prueba ADF (Augmented Dickey-Fuller) # Prueba de Dickey-Fuller aumentada (ADF) adf_test &lt;- adf.test(ts_diaria) ## Warning in adf.test(ts_diaria): p-value smaller than printed p-value print(adf_test) ## ## Augmented Dickey-Fuller Test ## ## data: ts_diaria ## Dickey-Fuller = -5.714, Lag order = 7, p-value = 0.01 ## alternative hypothesis: stationary Hipótesis nula: Los datos son no estacionarios Hipótesis alterna: Los datos son estacionarios La prueba indica que p-value es menor a 0.05 por lo que se asume que la serie efectivamente es estacionaria. Esto implica que las propiedades estadísticas de esta serie (media, varianza, autocorrelación) no cambian en el tiempo. 2.6 Diferenciación Para el proceso de diferenciacion se generaron 2 hipotesis de trabajo para la prueba de Dickey-Fuller. Dado que el resultado de la prueba de Dickey-Fuller aumentada (ADF) arrojó un p-valor de 0.01, podemos rechazar la hipótesis nula de que la serie tiene una raíz unitaria, lo que indica que la serie es estacionaria. En consecuencia, no es necesario aplicar técnicas de diferenciación, ya que la serie no presenta una tendencia sistemática ni una varianza creciente que requiera ser eliminada para su análisis. Esta conclusión también puede ser respaldada visualmente mediante la gráfica de la serie y la función de autocorrelación (ACF), que muestran un comportamiento estable en el tiempo y una rápida disminución de las autocorrelaciones 2.7 Conclusión La descomposición confirma que el ausentismo laboral tiene una estructura estacional fuerte y una tendencia variable, además de una cantidad de ruido considerable. Esto respalda la necesidad de utilizar modelos que capturen tanto la estacionalidad como la tendencia. Además, el resultado del ADF que indicó estacionariedad sugiere que la serie ya es adecuada para modelado sin diferenciación adicional. "],["predicciones.html", "Capítulo 3 Predicciones 3.1 Método Holt-Winters 3.2 Predicción próximos 7 días 3.3 Conclusión aplicacion metodología Holt-Winters", " Capítulo 3 Predicciones 3.1 Método Holt-Winters El método Holt-Winters es una técnica de pronóstico de series temporales que incorpora elementos de tendencia y estacionalidad, extendiendo el método de suavizado exponencial simple. Implica tres parámetros de suavizado que se ajustan al nivel, la tendencia y la componente estacional de la serie temporal. El método de Holt Winters es utilizado para realizar pronósticos del comportamiento de una serie temporal a partir de los datos obtenidos anteriormente. El método se basa en un algoritmo iterativo que a cada tiempo (mes o semana) realiza un pronóstico sobre el comportamiento de la serie en base a promedios debidamente ponderados de los datos anteriores. Cómo resultado del capítulo 2, se construyó una serie temporal diaria con frecuencia semanal (7 días), que comienza en la semana 1 del ciclo 1 y termina en la semana 53 del ciclo 1. Los valores tienen una distribución asimétrica con muchos ceros (25% de los datos son 0) pero con algunos valores muy altos (hasta 168). #Se verifican características de los datos class(ts_diaria) ## [1] &quot;ts&quot; start(ts_diaria) ## [1] 1 1 end(ts_diaria) ## [1] 53 1 frequency(ts_diaria) ## [1] 7 summary(ts_diaria) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.00 0.00 7.00 14.04 16.00 168.00 El siguiente gráfico muestra que los datos presentan un comportamiento errático con valores altos de ausentimos en algunas semanas. Sin embargo, la línea generada no muestra una tendencia hacía el aumento o disminución. Para analizar el comportamiento de los datos se intenta realizar una transformación logarítmica. Sin embargo, debido a que la variable de ausencia tiene valores de 0, esta transformación no es posible ya que cuando se trabaja con series temporales donde la variable objetivo contiene ceros, las transformaciones tradicionales como el logaritmo fallan porque log(0) = -∞ En ese sentido, se debe recurrir a otro tipo de transformación que no genere modificaciones profundas en los datos, para ello, se hace uso de una técnica Una desventaja de esta transformación es que puede crear un “hueco” artificial entre los ceros transformados y los valores pequeños positivos como se muestra en el gráfico. Adicionalmente, los coeficientes en modelos ajustados a datos transformados requieren interpretación cuidadosa. Sin embargo estos “huecos” son una representación fiel de la discontinuidad matemática entre cero y valores positivos, además de un indicador visual de la presencia de ceros en los datos originales que puede ser una propiedad deseable en muchos casos, ya que marca claramente la diferencia entre “cero” y “casi cero”. A continuación se aplica el método Holt-Winters y a partir de un gráfico intentamos observar como el modelo se ajusta a los datos originales. Posteriormente, se aplica el método a los datos tranformados. #Se crea una nueva serie de datos muy cerca de los datos originales # Configurar área de gráfico con 2 filas y 1 columna par(mfrow = c(2, 1), mar = c(4, 4, 2, 1)) # márgenes ajustados # Primera gráfica (serie original) hw &lt;- HoltWinters(ts_diaria) plot(hw, main = &quot;Suavizamiento Holt-Winters - Serie Original&quot;) # Segunda gráfica (serie transformada) hwt &lt;- HoltWinters(ts_transf) plot(hwt, main = &quot;Suavizamiento Holt-Winters - Serie Transformada&quot;) # Restaurar configuración gráfica par(mfrow = c(1, 1)) Cómo se observa en el gráfico, el método Holt-Winter aplicado a los datos originales (ts_diaria) no se ajusta completamente a los picos de ausentismo que se presentan en algunos días. Una vez se aplica el suavizamiento (ts_transform), con el método antes descrito, vemos que el modelo tiende a ajustarse mejor al comportamiento original, aunque no del todo. # Configurar área de gráficos (2 filas, 1 columna) par(mfrow = c(2, 1), mar = c(4, 4, 2, 1)) # Ajustar márgenes # Gráfico del modelo original plot(fitted(hw), main = &quot;Modelo Holt-Winters - Serie Original&quot;, ylab = &quot;Valores&quot;, xlab = &quot;Tiempo&quot;) # Gráfico del modelo transformado plot(fitted(hwt), main = &quot;Modelo Holt-Winters - Serie Transformada&quot;, ylab = &quot;Valores Transformados&quot;, xlab = &quot;Tiempo&quot;) # Restaurar configuración gráfica par(mfrow = c(1, 1)) Observed (Observada): La serie con el modelo Holt Winters presenta variaciones, con múltiples picos que podrían corresponder a eventos puntuales de alto ausentismo. La serie muestra fluctuaciones regulares, lo que sugiere la presencia de estacionalidad y posiblemente una leve tendencia. Trend (Tendencia): La tendencia es irregular, pero revela periodos de aumento y disminución del ausentismo a lo largo del tiempo. Se observan tramos donde el nivel general de ausentismo se incrementa al inicio de la semana y antes del fin de semana Seasonal (Estacionalidad): La componente estacional es clara y bien definida, con un patrón cíclico semanal o cercano al semanal (como fue el caso de la descomposición diaria por día de la semana). Esto sugiere que existe un patrón repetitivo y consistente en el ausentismo, posiblemente relacionado con el inicio o fin de semana, en los que los niveles de ausentismo tienden a aumentar. Random (Ruido aleatorio): El componente aleatorio muestra picos aislados, lo que indica eventos impredecibles que no pueden explicarse ni por la tendencia ni por la estacionalidad. Es de notar que comparado con los datos originales este metodo de suavizamiento disminuye el ruido presente en la serie 3.2 Predicción próximos 7 días A continuación se genera una predicción para los siguientes siete días usando los resultados del modelo. #Se realiza una predicion para los proximos 7 días pred=predict(hw, 7, prediction.interval = TRUE) pred ## Time Series: ## Start = c(53, 2) ## End = c(54, 1) ## Frequency = 7 ## fit upr lwr ## 53.14286 27.4334029 74.75449 -19.88768 ## 53.28571 16.6943222 64.10558 -30.71693 ## 53.42857 8.5784673 56.08471 -38.92778 ## 53.57143 10.6400895 58.24624 -36.96606 ## 53.71429 -0.8931247 46.81796 -48.60421 ## 53.85714 -0.9199175 46.90122 -48.74106 ## 54.00000 26.4335818 74.37000 -21.50283 Para finalizar se hace una visualización de los resultados obtenidos. #se visualizan los valores pronosticados para los proximos 7 dias plot(hw,pred) En este último gráfico se observa en negro la serie real y en rojo la previsto, la barra punteada es la ventana pronosticada para los próximos 7 días. Al trazar cada pronóstico, se puede ver que el método de Holt muestra claramente la captura de un componente de tendencia. 3.3 Conclusión aplicacion metodología Holt-Winters La metodología Holt-Winters es una técnica de pronóstico que captura de manera efectiva las tendencias y la estacionalidad en los datos de series temporales. En la base de datos de Ausentismo se concluye que la nueva serie de datos aplicando el método de suavizamiento exponencial permitió disminuir los picos que se observaban en el modelo original permitiendo disminuir el ruido y mostrando un modelo predictivo que apunta al ausentismo laboral en el comienzo y final de la semana. En este ejemplo especifico al aplicar la metodología se esboza un componente de tendencia y se determina un patrón de estacionalidad para el ausentismo presente en la serie de tiempo entre julio de 2007 a julio de 2010. "],["modelo-arima.html", "Capítulo 4 Modelo ARIMA 4.1 Generación del modelo 4.2 Análisis de los residuos 4.3 Punto de cambio (AMOC) 4.4 Predicción 4.5 Conclusiones", " Capítulo 4 Modelo ARIMA El modelo ARIMA (AutoRegressive Integrated Moving Average) es una herramienta estadística utilizada para modelar y predecir series de tiempo univariadas. Su nombre proviene de los tres componentes principales que lo conforman: AR (AutoRegresivo): Indica que la variable dependiente se explica por sus propios valores pasados. I (Integrado): Se refiere al número de diferenciaciones necesarias para que la serie se vuelva estacionaria. MA (Media Móvil): Representa la dependencia entre el valor actual de la serie y los errores residuales pasados. El modelo ARIMA se denota como ARIMA (p, d, q), donde: p: número de términos autorregresivos (AR). d: número de diferencias requeridas para hacer estacionaria la serie. q: número de términos de media móvil (MA). Para que un modelo ARIMA sea válido, es necesario que se cumplan ciertos supuestos fundamentales. En primer lugar, la serie de tiempo debe ser estacionaria, lo que implica que sus propiedades estadísticas, como la media, la varianza y la covarianza, se mantengan constantes a lo largo del tiempo. En caso de que la serie no sea estacionaria, debe poder transformarse en una serie estacionaria mediante procedimientos como la diferenciación. En segundo lugar, se requiere que los residuos del modelo —es decir, las diferencias entre los valores observados y los estimados— se comporten como ruido blanco. Esto significa que deben ser aleatorios, con media cero, varianza constante y sin correlación entre ellos. El cumplimiento de estos supuestos es esencial para garantizar la validez de las inferencias y pronósticos derivados del modelo ARIMA. Partiendo de los resultado del capítulo 2, se estableció que la serie de tiempo asociada al caso de ausentismo es estacionaria según el resultado del test Dickey-Fuller. A continuación se aplica el modelo Arima 4.1 Generación del modelo modelo_arima&lt;-auto.arima(ts_diaria) modelo_arima ## Series: ts_diaria ## ARIMA(0,0,0)(0,0,2)[7] with non-zero mean ## ## Coefficients: ## sma1 sma2 mean ## 0.0992 0.1259 13.9487 ## s.e. 0.0564 0.0534 1.5605 ## ## sigma^2 = 603.5: log likelihood = -1685.04 ## AIC=3378.08 AICc=3378.19 BIC=3393.68 A continuación vamos a explicar los resultados del modelo ARIMA: ARIMA(0,0,0) → Componente no estacional: p=0: no hay términos autorregresivos. d=0: no se aplicó diferenciación (la serie ya era estacionaria). q=0: no hay términos de media móvil no estacionales. (0,0,2)[7] → Componente estacional con periodicidad 7 (Días de la semana) indicando un P=0, D=0, Q=2. Es decir, que hay dos términos de media móvil estacional. En ese caso el valor 7 indica que se detectó una estacionalidad semanal, común en datos diarios con patrón semanal como el ausentismo laboral. with non-zero mean: Indica que el modelo incluye una constante, es decir, la serie tiene una media distinta de cero. Usando la notación ARIMA el modelo ajustado se puede escribir como: Yd=0.0992 Yt−1+0.1259 Yt−2+13.9487et−1+E Este modelo detecta un patrón semanal en la serie de ausentismo, lo que tiene sentido si hay diferencias sistemáticas entre días de la semana (como más ausencias los lunes que los viernes, según lo observado en capítulos anteriores). No se encontraron tendencias o ciclos no estacionales, y la serie fue tratada como estacionaria desde el inicio. Si los residuos del modelo pasan las pruebas de diagnóstico (como Ljung-Box), podría considerarse como un modelo adecuado para pronóstico. 4.2 Análisis de los residuos Se requiere que los residuos del modelo —es decir, las diferencias entre los valores observados y los estimados— se comporten como ruido blanco. Esto significa que deben ser aleatorios, con media cero, varianza constante y sin correlación entre ellos. El cumplimiento de estos supuestos es esencial para garantizar la validez de las inferencias y pronósticos derivados del modelo ARIMA. Para comprobar si los residuos de un modelo ARIMA aplicado a ausentismo laboral, se comportan como ruido blanco se grafican los residuos y la función de autocorrelación ACF, como se muestra a continuación. checkresiduals(modelo_arima) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(0,0,0)(0,0,2)[7] with non-zero mean ## Q* = 9.8081, df = 12, p-value = 0.6328 ## ## Model df: 2. Total lags used: 14 La función de autocorrelación (ACF): mide la correlación entre una serie de tiempo y sus valores retrasados. La autocorrelacion proporciona información de como una observación del ausentismo influye en las siguientes observaciones. Al trazar esta serie diferenciada, se observa un valor alto en el lag 0, lo cuál es normal pues se compara la serie con sigo misma y se espera que los residuos estén correlacionados con ellos mismos. Para determinar el valor de q en un modelo ARIMA, se puede mirar el gráfico ACF y buscar el primer retraso que tiene una correlación significativa (es decir en donde se sobrepasen las lineas punteadas). En esta grafica se observa un Lag relevante de 21, indicando que hay una correlación significativa entre los valores actuales y los de hace 3 periodos (3 semanas atras). Este valor es interesante y puede estar asociado a la rotación de turnos (diario, tarde, nocturno). En general, esto mostraría que hay información no explicada por el modelo. Para la validacion del modelo se analiza que los residuos sean Ruido Blanco, es decir, que los residuos se distribuyen normalmente y no hay autocorrelación entre ellos. Para ello, se aplica la prueba de Shapiro para normalidad y la de Ljung-Box para mirar si los residuales cumplen el supuesto de independencia o estan autocorrelacionados hist(resid(modelo_arima), main = &quot; Histrograma de residuos&quot;) qqnorm(resid(modelo_arima)) qqline(resid(modelo_arima), col = &quot;blue&quot;) El Q-Q plot muestra que los puntos están dispersos en las colas (por ejemplo, hacia el extremo superior), esto puede implicar que hay más valores extremos de lo que se esperaría bajo una normalidad perfecta, y por ende podría ser una señal de que los residuos no son normales, lo cual puede sugerir que el modelo ARIMA no está capturando completamente la dinámica de la serie temporal y que se podría necesitar ajustes adicionales. Box.test(resid(modelo_arima), lag = 10, type = &quot;Ljung-Box&quot;) ## ## Box-Ljung test ## ## data: resid(modelo_arima) ## X-squared = 7.3853, df = 10, p-value = 0.6886 Con la prueba de Ljung-Box, se evalúa si hay o no autocorrelación en los residuos, en este caso aplicada hasta 10 rezagos para que sea más significativa: Hipótesis H0: No hay autocorrelación de los residuos H1: Existe autocorrelación de los residuos Como el P-value (0.6886) es mayor a 0.05 no se rechaza H0. En ese caso si se cumple la condición de los residuos son ruido blanco y no muestran autocorrelación significativa, siendo una buena señal de que el modelo ha capturado bien la estructura de la serie hasta los primeros 10 rezago. 4.3 Punto de cambio (AMOC) A continuación se usa la función cpt.mean() del paquete changepoint en R, específicamente con el método “AMOC” (At Most One Change), para detectar cambios en la media de una serie temporal. mval&lt;-cpt.mean(ts_diaria,method = &quot;AMOC&quot;) cpts(mval) ## [1] 63 El resultado muestra que la serie ts_diaria tiene una ruptura (cambio estructural) en el valor medio en el dato número 63. Esto sugiere que antes y después de ese punto, los valores de la serie tienen medias significativamente diferentes. El método “AMOC” busca una única ruptura (At Most One Change), y detectó que la mejor ubicación para dividir la serie en dos segmentos con medias distintas es en el punto 63. A continuación se gráfica el resultado para ver el punto de ruptura. plot(mval, type = &quot;l&quot;, cpt.col = &quot;blue&quot;, xlab = &quot;Value&quot;, cpt.width = 4, main = &quot;default penalty&quot;) La gráfica muestra la serie con una línea vertical en el punto donde ocurre el cambio, y líneas horizontales indicando las medias antes y después. En este caso el valor 63 de la serie corresponde a la fecha: 2007-03-04, indicando un cambio significatoco en este día. Esta información puede ayudar a decidir si necesitas transformar o dividir la serie antes de ajustar un modelo ARIMA. 4.4 Predicción Estos son los datos de ausentismo laboral proyectados para los siguientes 12 días utilizando el paquete forecast para la serie diaria. pred&lt;-forecast(modelo_arima, h=12, level = 95) pred ## Point Forecast Lo 95 Hi 95 ## 53.14286 20.83206 -27.31579 68.97990 ## 53.28571 12.74445 -35.40339 60.89229 ## 53.42857 12.98373 -35.16411 61.13157 ## 53.57143 11.91021 -36.23764 60.05805 ## 53.71429 11.38556 -36.76228 59.53341 ## 53.85714 11.38556 -36.76228 59.53341 ## 54.00000 12.01959 -36.12825 60.16743 ## 54.14286 9.06356 -39.32047 57.44759 ## 54.28571 13.35275 -35.03128 61.73677 ## 54.42857 14.62271 -33.76131 63.00674 ## 54.57143 13.04233 -35.34170 61.42636 ## 54.71429 12.51469 -35.86934 60.89871 plot(pred, main=&quot; &quot;, ylab=&quot;Horas&quot;, col=&quot;deepskyblue&quot;, xlab=&quot;Días&quot;) title(main=&quot;Predicción de Ausentismo laboral&quot;) En esta grafica se especifica el horizonte de pronóstico de h periodos por delante para que se realicen las predicciones de ausentismo laboral. En este caso correspondiente a 12 días. En una análisis visual inicial, la predicción parace guardar concordancia con el pronóstico del resto de la serie. A continuación se hace un análisis de los valores atípicos en la serie, para lo cuál se hace uso de la función tso(), que busca outliers que afecten la estructura de la serie, especialmente aquellos que pueden influir negativamente en el ajuste de modelos ARIMA. Identifica: AO = Additive Outlier: un valor atípico puntual. LS = Level Shift: un cambio repentino y permanente en el nivel de la serie. TC = Temporary Change: un cambio brusco pero transitorio. dat.ts&lt;- ts(ts_diaria,frequency=1) data.ts.outliers &lt;- tso(dat.ts) ## Warning in locate.outliers.iloop(resid = resid, pars = pars, cval = cval, : ## stopped when &#39;maxit.iloop&#39; was reached ## Warning in locate.outliers.iloop(resid = resid, pars = pars, cval = cval, : ## stopped when &#39;maxit.iloop&#39; was reached ## Warning in locate.outliers.oloop(y = y, fit = fit, types = types, cval = cval, ## : stopped when &#39;maxit.oloop = 4&#39; was reached plot(data.ts.outliers) En el gráfico se observa: Línea gris: serie original (ts_diaria), sin ajuste. Línea azul: serie ajustada tras identificar y corregir los outliers. Puntos rojos: valores atípicos detectados (tipos como AO, LS o TC). En general se observa que hay múltiples picos atípicos detectados a lo largo de la serie, donde los puntos rojos indican que en esos días hubo valores que no siguen el comportamiento esperado por el modelo ARIMA. Estos valores han sido ajustados en la línea azul, suavizando la serie. Esto indica que la serie contiene eventos que podrían ser anómalos, errores de registro, o situaciones excepcionales (como ausencias masivas, festivos especiales, etc.). En el gráfico inferior se observa que varios outliers tienen efectos importantes y persistentes (altas barras).Esos valores distorsionan la dinámica general de la serie y deben considerarse al ajustar o interpretar un modelo de predicción. 4.5 Conclusiones El modelo ARIMA es una herramienta fundamental para el análisis de series temporales, ya que permite modelar y pronosticar variables que presentan patrones a lo largo del tiempo. Su estructura flexible, basada en componentes autorregresivos, de media móvil y diferenciación, lo hace adaptable a diversas situaciones. En este caso el ausentismo laboral no ocurre de forma aleatoria: puede estar influido por factores cíclicos, estacionales, o por comportamientos repetitivos a lo largo del tiempo (como más ausencias en invierno o al final de mes). El modelo permite capturar tendencias subyacentes, fluctuaciones cíclicas y dinámicas pasadas de manera efectiva, lo cual es crucial para comprender el comportamiento histórico de una variable y anticipar su evolución futura, se proyecta el futuro de manera cuantitativa y con intervalos de confianza, esto es crucial para anticipar cuándo se dará mayor ausentismo, preparar recursos humanos o personal de reemplazo y tomar decisiones de planificación con tiempo. Acá el modelo ARIMA es importante porque transforma los datos históricos de ausentismo en información procesable, predicciones útiles y mejoras en las decisiones organizacionales, pues permite entender la evolución del ausentismo y actuar antes de que afecte la operación de la empresa. En términos generales, el modelo ARIMA reduce la incertidumbre, optimiza recursos y mejora la eficiencia operativa, convirtiéndose en un aliado estratégico en entornos donde el tiempo y la previsión son factores críticos. "],["modelo-prophet.html", "Capítulo 5 Modelo Prophet 5.1 Generacion del modelo 5.2 Predicción", " Capítulo 5 Modelo Prophet El modelo Prophet consiste en usar un modelo descomponible de series temporales y se estima utilizando un enfoque bayesiano para permitir la selección automática de los puntos de cambio y otras características del modelo y tiene en cuenta tres factores importantes: la tendencia, la estacionalidad y los días festivos. Estos componentes son combinados en la ecuación y(t) = g(t) + s(t) + h(t) +εt. El valor de y pronosticado por el modelo en el momento t viene dado por la función y(t) y tiene cuatro componentes: Componente de crecimiento o la tendencia generalg (t): Modela los cambios no periódicos. Los nudos (o puntos de cambio) para la tendencia lineal a trozos son seleccionados automáticamente si no se especifican explícitamente. Opcionalmente, se puede utilizar una función logística para establecer un límite superior en la tendencia Componente estacional s(t): representa la suma de todos los componentes periódicos y consiste en términos de Fourier de los periodos relevantes. Por defecto, se utiliza el orden 10 para la estacionalidad anual y el orden 3 para la estacionalidad semanal. Efectos de los días festivos h(t): representa uno o mas días que ocurren en calendarios irregulares o se pueden añadir como variables ficticias simples. Error εt: es el término que engloba todos los demás cambios que no ajustan los demás componentes del modelo. Es el termino de ruido blanco. El modelo se estima utilizando un enfoque bayesiano para permitir la selección automática de los puntos de cambio y otras características del modelo. 5.1 Generacion del modelo Debido a que el modelo Prophet no opera directamente sobre objetos del tipo ts de R, sino sobre data frames, se utiliza una versión tabular de la serie temporal (serie_diaria). Para que Prophet pueda identificar correctamente las variables de fecha y valor, es obligatorio que las columnas se llamen ds (date stamp) y y (value). Por lo tanto, se realiza una transformación previa del conjunto de datos, renombrando las columnas correspondientes. Esta preparación garantiza que Prophet interprete adecuadamente la estructura temporal de la serie para modelar tendencias, estacionalidades y generar pronósticos de forma efectiva. A continuación se genera el modelado de la serie temporal diaria de ausencia laboral en horas, y que incluye un componente de estacionalidad semanal para capturar patrones con esa frecuencia. Debido a las características de los datos, se deicidió incluir un componentes mensual que odría mejorar el modelo. El siguiente código muestra la inicialización del modelo y su configuración. #Debido a que prophet se ejecuta sobre un dataframe y no un archivo tipo ts se usa serie_diaria. #Prophet requiere usar nombres específicos para las columnas, se hace la respectiva transformación. # Validar columnas names(serie_diaria) &lt;- c(&quot;ds&quot;, &quot;y&quot;) # Filtrar valores válidos serie_diaria &lt;- serie_diaria[!is.na(serie_diaria$ds) &amp; !is.na(serie_diaria$y), ] # Confirmar que hay datos después del filtrado if (nrow(serie_diaria) == 0) { stop(&quot;El dataframe `serie_diaria` está vacío después de limpiar valores NA.&quot;) } # Asegurar que `ds` es Date y `y` es numérico serie_diaria$ds &lt;- as.Date(serie_diaria$ds) serie_diaria$y &lt;- as.numeric(serie_diaria$y) # Inicializar modelo model_prophet &lt;- prophet::prophet ( weekly.seasonality = TRUE, daily.seasonality = FALSE, yearly.seasonality = FALSE, seasonality.mode = &#39;additive&#39;, seasonality.prior.scale = 10 ) # Agregar estacionalidad mensual model_prophet &lt;- add_seasonality( model_prophet, name = &quot;monthly&quot;, period = 30.5, fourier.order = 3 ) # Ajustar el modelo model_prophet &lt;- fit.prophet(model_prophet, serie_diaria) Interpretación del modelo Prophet $growth = “linear”:El modelo asume que la tendencia de la serie crece de manera lineal con el tiempo. Si quisieras un crecimiento que se estabiliza (sigmoide), usarías “logistic”. $changepoints = NULL y $n.changepoints = 25: Prophet no ha identificado aún los puntos exactos de cambio en la tendencia (aún no se ha entrenado o guardado esa parte), pero está configurado para buscar hasta 25 posibles puntos de cambio dentro del rango permitido. $changepoint.range = 0.8 Los changepoints (cambios estructurales en la tendencia) se buscarán dentro del 80% inicial de la serie temporal. Esto previene que el modelo ajuste cambios cerca del final, donde hay más incertidumbre. $yearly.seasonality = “auto”, $weekly.seasonality = “auto”, $daily.seasonality = “auto”: Prophet intentará detectar automáticamente si hay estacionalidades de tipo anual, semanal o diaria, en función de la longitud de la serie y la frecuencia de los datos. En el caso de ausentismo se entiende que los datos son diarias y según se analizo en capítulos anteriores la estacionalidad es semanal. $holidays = NULL: No se han incluido festivos o eventos externos como regresores adicionales. Puedes añadirlos manualmente si crees que afectan la serie (por ejemplo, días no laborales en una serie de ausentismo). $seasonality.mode = “additive”: La estacionalidad se suma a la tendencia (modelo aditivo). Si los efectos estacionales crecen o decrecen con la tendencia, podrías usar el modo “multiplicative”. $changepoint.prior.scale = 0.05: Controla qué tan flexible es el modelo para detectar cambios de tendencia. Un valor bajo como 0.05 penaliza cambios bruscos, suavizando la tendencia. Valores más altos permiten más cambios estructurales. $seasonality.prior.scale = 10: Determina cuánta libertad tiene el modelo para ajustar estacionalidades. Un valor de 10 es bastante flexible. $interval.width = 0.8: Los intervalos de predicción se generarán con un 80% de confianza. $uncertainty.samples = 1000: Se generan 1000 simulaciones para calcular la incertidumbre en los pronósticos. $mcmc.samples = 0: No se usó muestreo bayesiano MCMC. Prophet ajusta los parámetros con máxima verosimilitud de forma más rápida (por defecto). 5.2 Predicción A continuación se procede a hacer la predicción a partir del modelo entrenado. Sin embargo, hay que tener en cuenta que las predicciones a largo plazo (como un año) se vuelven más inciertas, porque no hay datos reales para “anclar” la tendencia reciente y el modelo Prophet proyecta con base en la tendencia lineal y estacionalidades pasadas, que pueden cambiar. De igual forma, los intervalos de confianza (yhat_lower, yhat_upper) se vuelven más amplios. Por esto, para este ejercicio solo se pronostica para un periodo de 90 días (3 meses), que corresponderían al primer trimestre del año 2008. De esta forma las predicciones están más cerca de los datos conocidos y la estacionalidad semanal se proyecta de forma más confiable con menor acumulación de error. En primera instancia se usa la función make_future_dataframe que crea un dataframe con fechas futuras que extiende el conjunto de datos históricos del modelo, pero no hace predicciones. En este caso extiende las fechas por 90 días en la columna ds incluyendo las fehcas de los datos originales. # Construcción de dataframe con las fechas de los futuros periodos future &lt;- make_future_dataframe(model_prophet, periods = 90) tail(future) ## ds ## 450 2008-03-25 ## 451 2008-03-26 ## 452 2008-03-27 ## 453 2008-03-28 ## 454 2008-03-29 ## 455 2008-03-30 A continuación se calculan las predicciones y_hat y los intervalos de incertidumbre para las fechas en future a partir del modelo entrenado (model_prophet) y lo aplica sobre las fechas future. El dataframe devuelto (forecast) incluye las columnas: ds (fecha) yhat (predicción) yhat_lower &amp; yhat_upper (intervalo de confianza) # Predicción de los valores futuros según el modelo generado, la variable y_hat es la predicción forecast &lt;- predict(model_prophet, future) tail(forecast[c(&#39;ds&#39;, &#39;yhat&#39;, &#39;yhat_lower&#39;, &#39;yhat_upper&#39;)]) ## ds yhat yhat_lower yhat_upper ## 450 2008-03-25 26.815922 -0.1777552 58.97647 ## 451 2008-03-26 24.641244 -5.3191383 55.30522 ## 452 2008-03-27 12.628969 -16.3998575 39.77223 ## 453 2008-03-28 14.287679 -13.8409764 43.27521 ## 454 2008-03-29 -1.746538 -31.7534695 27.03004 ## 455 2008-03-30 -2.857669 -32.1631176 26.19366 # Grafica plot(model_prophet, forecast) El gráfico de la predcción del modelo muestra una oscilación clara y regular en forma de picos y valles que se repite cada 7 días, lo cual indica que el modelo detectó una estacionalidad semanal, como se esperaba. Hay varios puntos negros muy por encima de la línea azul y del intervalo de confianza. Estos son días con picos inusuales de ausentismo, que el modelo no logra predecir bien. Por ejemplo, a mediados de 2007 y de nuevo hacia fines de año. Esto se vió también en el capítulo 4 cuando se construyó el modelo ARIMA. Adicionalmente, no se observó una tendencia claramente creciente o decreciente pues la línea azul parece mantenerse estable, lo que indica que Prophet no identificó una tendencia lineal fuerte en los datos. Respecto a la predicción, se observa que el intervalo de incertidumbre se ensancha gradualmente, lo que es esperado: el modelo es menos confiable mientras más lejos proyecta. # se crea un grafico para observar la tendencia, estacionalidad semanal y estacionalidad anual prophet_plot_components(model_prophet, forecast) El gráfico de descomposión confirma los resultados mencionados anteriormente, a nivel semanal se evidencia el efecto del ausentismo a inicios de semana, con un mayor número de horas y menos frecuente hacía el final de la semana. A nivel anual pareciera haber una tendencia hacía la disminución en el número de horas de ausentismo. De igual manera, la predicción muestra el aumento en la incertidumbre a medida que se amplia el horizonte de predicción. A nivel mensual pareciera indicar un patrón constante en todas las semanas, excepto en la última semana del mes con una disminución en el total de horas de ausentismo. # Se miran las escalas temporales con un grafico interactivo dyplot.prophet(model_prophet, forecast) ## Warning: `select_()` was deprecated in dplyr 0.7.0. ## ℹ Please use `select()` instead. ## ℹ The deprecated feature was likely used in the prophet package. ## Please report the issue at ## &lt;https://github.com/facebook/prophet/issues&gt;. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning ## was generated. "],["capitulo-6-comparacion-de-modelos.html", "Capítulo 6 Capitulo 6 Comparacion de modelos 6.1 Métricas a implementar", " Capítulo 6 Capitulo 6 Comparacion de modelos Para evaluar el desempeño de distintos enfoques en la predicción del ausentismo laboral, se realizó una comparación entre tres modelos ampliamente utilizados en series de tiempo: ARIMA, ETS (suavizamiento exponencial) y Prophet. Cada uno de estos modelos incorpora supuestos y mecanismos distintos para capturar patrones como la tendencia, la estacionalidad y la variabilidad residual. El objetivo de esta comparación es identificar cuál de ellos ofrece mejores capacidades de ajuste y predicción a partir de los datos históricos disponibles. Para ello, se utilizó un conjunto de entrenamiento con datos diarios, y se aplicaron métricas de desempeño como el RMSE y MAE, además de visualizar sus pronósticos para un horizonte de tres meses. Esta evaluación permite establecer fortalezas y limitaciones relativas de cada enfoque, facilitando una selección informada del modelo más adecuado según el contexto y los objetivos analíticos. 6.1 Métricas a implementar Para la comparación de modelos se utilizan las siguientes métricas: Error medio (ME – Mean Error) : Es el promedio de todos los errores de un conjunto de observaciones.Puede estar sesgada debido ala compensacion de errores positivos y negativos pero sirve como indicador de asimetrias en la distribucion de los errores La raíz del error cuadrático medio (RMSE – Root Mean Square Error): Es la desviación estándar de los errores y tiene la ventaja de tener las mismas unidades que la variable predicha, por lo que es más fácil de interpretar directamente. Error absoluto medio (MAE – Mean Absolute Error): Corrige la inexactitud del error medio al poseeer valores absolutos, da un promedio de la magnitud absoluta de todos los valores de los errores, sin importar si eran positivos o negativos.protege los valorrs atipicos Error porcentual medio (MPE – Mean Percentage Error ): Es el promedio de errores porcentuales por los que cada previsión difiere de sus correspondientes valores reales observados y no es una metrica adecuada para conjuntos de datos que contienen valores observados iguales a cero Error porcentual absoluto medio (MAPE – Mean Absolute Percentage Error): Esta metrica arregla el problema con la compensación de errores como lo hace el MAE pero funciona mejor si no hay extremos en los datos y no hay ceros. Error cuadrático medio (MASE – Mean Square Error): Corrige tambien las inexactitudes del error medio y comparado con el MAE otorga una mayor penalización en los errores de predicción grandes. Autocorrelacion (ACF1): Es un coeficiente de correlacion entre una observacion actual y sus valores retardados en distintos momentos. Mide la similitud entre la observacion actual y sus valores pasados, indicando la presencia de patrones o tendencias repetitivos en los datos. # Asegurarse que los datos tienen las columnas ds (fecha) y (valor) # Convertir el ts a tsibble para que pueda ser usado con la librería fable ts_diaria &lt;- as_tsibble(serie_diaria, index = ds) # Filtrar datos solo del año 2007 si fuera necesario (opcional si ya está limpio) ts_diaria &lt;- ts_diaria %&gt;% filter(year(ds) == 2007) # Dividir el conjunto: entrenamiento (enero a septiembre), test (octubre a diciembre) train &lt;- ts_diaria %&gt;% filter(ds &lt; ymd(&quot;2007-10-01&quot;)) test &lt;- ts_diaria %&gt;% filter(ds &gt;= ymd(&quot;2007-10-01&quot;)) # Ajustar los modelos con los datos de entrenamiento fit &lt;- train %&gt;% model( arima = ARIMA(y), ets = ETS(y), prophet = prophet(y ~ season(&quot;week&quot;)) ) # Predecir el mismo horizonte que test (ej: 92 días para octubre-diciembre) forecast_fit &lt;- forecast(fit, h = nrow(test)) # Visualizar comparación entre predicción y datos reales autoplot(forecast_fit, ts_diaria) + ggtitle(&quot;Comparación de modelos: predicción vs. datos reales&quot;) accuracy_table &lt;- forecast::accuracy(forecast_fit, test) print(accuracy_table) ## # A tibble: 3 × 10 ## .model .type ME RMSE MAE MPE MAPE MASE RMSSE ACF1 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 arima Test 1.40 26.7 12.8 -Inf Inf NaN NaN -0.0640 ## 2 ets Test 2.19 25.7 12.2 NaN Inf NaN NaN -0.127 ## 3 prophet Test -0.613 25.6 12.4 NaN Inf NaN NaN -0.131 6.1.0.1 Conclusiones Al comparar el desempeño de los modelos ARIMA, ETS y Prophet sobre el conjunto de prueba (octubre a diciembre de 2007), se observa que los tres modelos presentan errores similares en términos absolutos, aunque con algunas diferencias relevantes en su comportamiento. El modelo Prophet mostró el menor RMSE (25.6), lo que indica que, en promedio, sus errores más grandes fueron ligeramente menos severos que los de ETS (25.7) y ARIMA (26.7). En términos de MAE, el modelo ETS obtuvo el mejor desempeño (12.2), seguido muy de cerca por Prophet (12.4), mientras que ARIMA presentó el mayor error absoluto promedio (12.8), lo que lo posiciona como el modelo menos preciso en esta comparación. En cuanto al sesgo de las predicciones (ME), ARIMA y ETS tienden a sobreestimar los valores reales (ME positivo), mientras que Prophet mostró un leve sesgo negativo, indicando una ligera tendencia a subestimar las observaciones. No obstante, este sesgo en Prophet es pequeño y posiblemente no significativo en la práctica. Por otro lado, las métricas de error basadas en porcentajes (MPE y MAPE) y las escaladas respecto a modelos base (MASE y RMSSE) no son confiables en este caso por contar con valores reales iguales a cero, razón por la que muestran valores indefinidos (NaN) o infinitos (Inf). Esto afecta la estabilidad numérica de estas métricas. Para este tipo de series, se recomienda complementar con otras métricas como SMAPE o enfocarse en MAE y RMSE. Finalmente, el análisis de la autocorrelación de los residuos (ACF1) muestra que los tres modelos presentan valores cercanos a cero, lo cual sugiere que no hay una estructura significativa de autocorrelación en los errores, lo que es un buen indicio de adecuación del modelo. Aunque todos los modelos ofrecen un desempeño razonablemente similar, ETS y Prophet destacan como las mejores opciones para este caso específico, con Prophet ofreciendo un balance adecuado entre bajo error cuadrático medio y menor sesgo. "],["references.html", "References", " References [1] Mowday RT, Porter LW, Steers RM (2013) Employee organization linkages: the psychology of commitment, absenteeism, and turnover. Academic press, New York [2] De Stobbeleir KE, De Clippeleer I, Caniëls MC, Goedertier F, Deprez J, De Vos A, Buyens D (2018) The inside effects of a strong external employer brand: how external perceptions can influ ence organizational absenteeism rates. Int J Hum Resour Manag 29:2106–2136. [3] Gonzalez BD, Grandner MA, Caminiti CB, Hui SA (2018) Cancer survivors in the workplace: sleep disturbance mediates the impact of cancer on healthcare expenditures and work absenteeism. Support Care Cancer 26:4049–4055. [4] Kocakulah, M. C., Kelley, A. G., Mitchell, K. M., &amp; Ruggieri, M. P. (2016). Absenteeism problems and costs: causes, effects and cures. The International Business &amp; Economics Research Journal (Online), 15(3), 89. [5] D. Dua and C. Graff, “Absenteeism at work Data Set,” UCI Machine Learning Repository, 2019. [Online]. Available: https://archive.ics.uci.edu/ml/datasets/Absenteeism+at+work "],["redes-neuronales.html", "Capítulo 7 Redes Neuronales 7.1 Redes neuronales: ELMAN 7.2 Redes neuronales: JORDAN 7.3 Rendimiento Redes ELMAN y JORDAN", " Capítulo 7 Redes Neuronales Mediante el uso de modelos con series neuronales se puede tener una arquitectura que genera una memoria con sentido temporal lo que lo hace aplicable a las series de tiempo, se pueden tener varias neuronas que registran entradas y generan salidas a las capas del modelo, estas conexiones arbitrarias entre las neuronas permiten crear ciclos y temporalidad. Existen diferentes tipos de modelos de redes neuronales dependiendo de la forma como están dispuestas las entradas y las salida, los mas conocidos son la red neuronal recurrente (ELMAN) y la red neuronal con memoria a corto plazo (Jordan). #Debido a las transformaciones realizadas anteriormente en ts_diaria, se redefine nuevamente para evitar conflicto con la clase del objeto en las operaciones posteriores. # Agrupar por fecha y sumar las horas de ausencia (puede haber varias por día) serie_diaria &lt;- datos %&gt;% filter(!is.na(Fecha)) %&gt;% group_by(Fecha) %&gt;% summarise(Horas = sum(Absenteeism.time.in.hours, na.rm = TRUE)) %&gt;% arrange(Fecha) # Rellenar fechas faltantes (por si hay días sin datos) todas_las_fechas &lt;- data.frame( Fecha = seq.Date(min(serie_diaria$Fecha), max(serie_diaria$Fecha), by = &quot;day&quot;) ) serie_diaria &lt;- todas_las_fechas %&gt;% left_join(serie_diaria, by = &quot;Fecha&quot;) %&gt;% mutate(Horas = ifelse(is.na(Horas), 0, Horas)) ts_diaria &lt;- ts(serie_diaria$Horas, frequency = 7) En este ejercicio se trabaja nuevamente con la serie ts_diaria construida en el capítulo 2. class(ts_diaria) ## [1] &quot;ts&quot; Para el uso de redes neuronales se requiere de la normalización de los datos en formato serie de tiempo. A continuación se realiza la respectiva normalización. ts_norm &lt;- (ts_diaria-min(ts_diaria))/(max(ts_diaria)-min(ts_diaria)) plot(ts_norm, main=&quot;Serie de tiempo ausentismo datos normalizados&quot;,xlab=&quot;Tiempo&quot;, ylab=&quot;Z&quot;) Ahora comprobamos el tamaño del dataset para definir el tamaño del conjunto de datos de entrenamiento y de prueba. #Se comprueba el numero de filas totales del dataset. tamano_total&lt;-length(ts_norm) tamano_total ## [1] 365 Se define el conjunto de entrenamiento. #definicion set de entrenamiento tamano_train &lt;- round(tamano_total*0.8, digits = 0) train &lt;- 0:(tamano_train-1) train ## [1] 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ## [19] 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 ## [37] 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 ## [55] 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 ## [73] 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 ## [91] 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 ## [109] 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 ## [127] 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 ## [145] 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 ## [163] 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 ## [181] 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 ## [199] 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 ## [217] 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 ## [235] 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 ## [253] 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 ## [271] 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 ## [289] 288 289 290 291 Se define el conjunto de prueba #definicion set de prueba test &lt;- (tamano_train):tamano_total test ## [1] 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 ## [20] 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 ## [39] 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 ## [58] 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 Se crea un marco de datos con n columnas, cada una de las cuales se construye avanzando un valor de la serie en el futuro, a través de una variable de tipo zoo. y&lt;-as.zoo(ts_norm) x1&lt;-Lag(y,k=1) x2&lt;-Lag(y,k=2) x3&lt;-Lag(y,k=3) x4&lt;-Lag(y,k=4) x5&lt;-Lag(y,k=5) x6&lt;-Lag(y,k=6) x7&lt;-Lag(y,k=7) x8&lt;-Lag(y,k=8) x9&lt;-Lag(y,k=9) x10&lt;-Lag(y,k=10) x11 &lt;- Lag(y, k = 11) x12 &lt;- Lag(y, k = 12) ts_norm &lt;- cbind(y,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12) Se eliminan los valoers NA que pueden desplazar la serie anyNA(ts_norm) ## [1] TRUE ts_norm_Lag &lt;- ts_norm[-(1:12),] DT::datatable(ts_norm_Lag) anyNA(ts_norm_Lag) ## [1] FALSE Se definen por conveniencia los valores de entrada y salida de la red neuronal. #Luego definimos los valores de entrada y salida de la red neuronal: inputs &lt;- ts_norm_Lag[,2:13] outputs &lt;- ts_norm_Lag[,1] 7.1 Redes neuronales: ELMAN Se crea una red tipo ELMAN y proceder a entrenarla con los datos previamente definidos. fit&lt;-elman(inputs[train], outputs[train], size=c(5,4,3,2,1), learnFuncParams=c(1), maxit=10000) El tercer parámetro indica que queremos crear cincto capas ocultas, una con cinco neuronas y así sucesivamente hasta una última capa con una neurona. Esto se ajustó al ver que el rendimiento del modelo aplicando solo dos capas no era adecuado. Además, indicamos una tasa de aprendizaje de 1, y también un número máximo de iteraciones de 10.000. Con la función plotIterativeError podemos ver cómo ha evolucionado el error de red a lo largo de las iteraciones de entrenamiento y se encuentra que este tiende a 0,esto indica que el modelo ha logrado aprender una representación correcta de los datos. plotIterativeError(fit) Ahora se realiza una evaluación del modelo solo sobre el conjunto de entrenamiento. Esto es útil para evaluar el overfitting (comparando errores en entrenamiento vs prueba). 7.1.1 Desempeño del modelo ELMAN con datos de entrenamiento. # Se elimina el conjunto de test de las entradas y salidas de las neuronas para realizar el ajuste del modelo a los datos reales y_train &lt;- as.vector(outputs[-test]) predtrain1 &lt;- predict(fit, inputs[-test]) Aunque los modelos (como redes neuronales) aprenden mejor con datos normalizados, la evaluación y la interpretación de resultados (por ejemplo, errores absolutos, visualización de predicciones) deben hacerse en la escala original para que tengan sentido. El siguiente código realiza el proceso conocido como “desnormalización” o “re-escalado inverso” de los datos que han sido previamente normalizados. y_train&lt;-y_train*(max(ts_diaria)-min(ts_diaria))+min(ts_diaria) predtrain1&lt;-predtrain1*(max(ts_diaria)-min(ts_diaria))+min(ts_diaria) El gráfico muestra el ajuste del modelo de red neuronal ELMAN sobre los datos del conjunto de entrenamiento. La línea negra representa los valores reales del fenómeno analizado (en este caso, el ausentismo normalizado), mientras que la línea roja corresponde a las predicciones generadas por el modelo para esas mismas observaciones. Un buen ajuste se refleja en que ambas líneas estén cercanas y sigan una trayectoria similar, lo que indica que el modelo ha aprendido correctamente la estructura de los datos. n &lt;- min(length(y_train), length(predtrain1)) pt1 &lt;- plotly::plot_ly(x = 1:n, y = y_train[1:n], type = &#39;scatter&#39;, mode = &#39;lines&#39;, line = list(color = &#39;black&#39;), name = &#39;Datos reales&#39;) %&gt;% plotly::add_lines(x = 1:n, y = predtrain1[1:n], line = list(color = &#39;red&#39;), name = &#39;Predicciones&#39;) %&gt;% plotly::layout( title = &quot;Ajuste de las predicciones modelo ELMAN en datos de entrenamiento&quot;, xaxis = list(title = &quot;Observación&quot;), yaxis = list(title = &quot;Ausentismo normalizado&quot;) ) pt1 En este caso se evidencia el comportamiento de las 291 observaciones que hacen parte del dataset de entrenaiento y se observan ciertas diferencias. Aunque las predicciones tratan de ajustarse a los datos reales, no los siguen completamente bien, sobre todo se evidencia que no hay ausencias de 0 horas en la predicción. 7.1.2 Desempeño del modelo ELMAN con datos de prueba. Este conjunto de bloques de código evalúa el desempeño del modelo de red neuronal ELMAN sobre el conjunto de prueba. Primero, se extraen las salidas verdaderas (y_test) y se calculan las predicciones del modelo (predtest1) usando únicamente las observaciones que no formaron parte del conjunto de entrenamiento. Luego, ambas series —que previamente fueron normalizadas— se transforman nuevamente a su escala original mediante una operación de desnormalización basada en el rango de los datos originales (ts_diaria). # se elimina el conjunto de test de las entradas y salidas de las neuronas para realizar el ajuste del modelo a los datos reales y_test &lt;- as.vector(outputs[-train]) predtest1 &lt;- predict(fit, inputs[-train]) y_test&lt;-y_test*(max(ts_diaria)-min(ts_diaria))+min(ts_diaria) predtest1&lt;-predtest1*(max(ts_diaria)-min(ts_diaria))+min(ts_diaria) Finalmente, se genera un gráfico interactivo en el que se superponen los valores reales (línea negra) y las predicciones (línea roja) para cada observación del conjunto de prueba (62 Observaciones). Este gráfico permite evaluar visualmente qué tan bien el modelo ELMAN generaliza a datos nuevos, y si sus predicciones son razonablemente cercanas a los valores reales. pt2 &lt;- plotly::plot_ly(x = 1:length(y_test), y = y_test, type = &#39;scatter&#39;, mode = &#39;lines&#39;, line = list(color = &#39;black&#39;), name = &#39;Datos reales&#39;) %&gt;% plotly::add_lines(x = 1:length(predtest1), y = predtest1, line = list(color = &#39;red&#39;), name = &#39;Predicciones&#39;) %&gt;% plotly::layout(title = &quot;Ajuste de las predicciones modelo ELMAN en datos de prueba&quot;, xaxis = list(title = &quot;Observación&quot;), yaxis = list(title = &quot;Ausentismo&quot;)) pt2 Mientras que el gráfico basado en y_train y predtrain1 busca evaluar qué tan bien el modelo de red neuronal ELMAN fue capaz de aprender los patrones presentes en el conjunto de entrenamiento, el gráfico basado en y_test y predtest1 tiene un objetivo mucho más crítico: medir la capacidad de generalización del modelo a datos nunca antes vistos. Esto es importante porque un modelo que memoriza los datos de entrenamiento sin poder predecir con precisión sobre datos nuevos probablemente esté sobreajustado. En cambio, si las predicciones sobre el conjunto de prueba son buenas, podemos confiar en que el modelo será útil en contextos reales o futuros. Ambos gráficos se desnormalizan para facilitar la interpretación, pero su utilidad analítica es diferente: el primero es introspectivo (¿aprendió el modelo?), y el segundo es prospectivo (¿puede predecir bien?). En este caso, se ve que el modelo tuvo problemas con los datos atípicos y prediciendo los días de 0 horas de ausentismo. Lo mejor sería ajustar los hiperparámetros del modelo para tratar de obtener un mayor ajuste respecto a las métricas de rendimiento. 7.2 Redes neuronales: JORDAN La red Jordan es un tipo de red neuronal recurrente, donde parte de la salida del modelo se retroalimenta a sí misma en el siguiente paso temporal. Es útil para series temporales o datos secuenciales, ya que puede recordar patrones del pasado inmediato. Se solicitan 10 capas ocultas y un factor de tasa de aprendizaje de 1. El resultado también se parcialmente a la serie original fit2&lt;-jordan(inputs[train], outputs[train], size=10, learnFuncParams=c(1), maxit=10000) plotIterativeError(fit2, main = &quot;Error iterativo para 5 neuronas&quot;) La gráfica anterior muestra que el error en el modelo JORDAN converge a cero, por lo que se espera un ajuste rápido del modelo. Esto indica que el modelo ha logrado aprender una representación correcta de los datos. 7.2.1 Desempeño del modelo JORDAN con datos de entrenamiento. Para identificar el desempeño del modelo JORDAN con datos de entrenamiento primero se elimina el conjunto de test de las neuronas con el objetivo de realizar el modelo con datos reales, después para interpretarlas correctamente (en horas reales de ausentismo) debemos desnormalizar, esto es invertir el escalamiento que hicimos al inicio por tanto las predicciones están en el mismo rango real. # Se elimina el conjunto de test de las entradas y salidas de las neuronas para realizar el ajuste del modelo a los datos reales y_j_train &lt;- as.vector(outputs[-test]) predtrain2 &lt;- predict(fit2, inputs[-test]) y_j_train&lt;-y_j_train*(max(ts_diaria)-min(ts_diaria))+min(ts_diaria) predtrain2&lt;-predtrain2*(max(ts_diaria)-min(ts_diaria))+min(ts_diaria) pt3 &lt;- plotly::plot_ly(x = 1:length(y_j_train), y = y_j_train, type = &#39;scatter&#39;, mode = &#39;lines&#39;, line = list(color = &#39;black&#39;), name = &#39;Datos reales&#39;) %&gt;% plotly::add_lines(x = 1:length(predtrain2), y = predtrain2, line = list(color = &#39;red&#39;), name = &#39;Predicciones&#39;) %&gt;% plotly::layout(title = &quot;Ajuste de las predicciones modelo JORDAN en datos de entrenamiento&quot;, xaxis = list(title = &quot;Observación&quot;), yaxis = list(title = &quot;Ausentismo normalizado&quot;)) pt3 En el grafico se muestra el modelo de red JORDAN junto con los datos de entrenamiento. Teniendo en cuenta que las líneas de puntos rojos serían las predicciones y la línea azul serían los valores reales, y el modelo funciona bien si ambas líneas están muy cerca, vemos que la línea roja (predicciones) sigue en parte la forma de la línea negra (datos reales), especialmente en zonas de baja variación, sin embargo, se observan varios picos exagerados en la línea de predicción, que no están presentes en los datos reales. Entre las observaciones entre 90 a 130 y cerca de 180, la red hace predicciones muy altas o negativas, incluso llegando a más de 600 o menos de -100, mientras que los datos reales se mantienen mucho más bajos. En general, el modelo intenta capturar la forma, pero sufre de inestabilidad o exceso de sensibilidad a ciertos patrones, lo cual puede ser síntoma de sobreajuste o mal entrenamiento. 7.2.2 Desempeño del modelo JORDAN con datos de prueba. Análogamente se realiza el mismo procedimiento que se hizo con los datos de entrenamiento, solo cambia los datos. En este momento se pone aprueba el modelo con el objetivo de identificar la precisión sobre los datos nuevos.  # se elimina el conjunto de test de las entradas y salidas de las neuronas para realizar el ajuste del modelo a los datos reales y_j_test &lt;- as.vector(outputs[-train]) predtest2 &lt;- predict(fit2, inputs[-train]) y_j_test&lt;-y_j_test*(max(ts_diaria)-min(ts_diaria))+min(ts_diaria) predtest2&lt;-predtest2*(max(ts_diaria)-min(ts_diaria))+min(ts_diaria) pt4 &lt;- plotly::plot_ly(x = 1:length(y_j_test), y = y_j_test, type = &#39;scatter&#39;, mode = &#39;lines&#39;, line = list(color = &#39;black&#39;), name = &#39;Datos reales&#39;) %&gt;% plotly::add_lines(x = 1:length(predtest2), y = predtest2, line = list(color = &#39;red&#39;), name = &#39;Predicciones&#39;) %&gt;% plotly::layout(title = &quot;Ajuste de las predicciones modelo JORDAN en datos de prueba&quot;, xaxis = list(title = &quot;Observación&quot;), yaxis = list(title = &quot;IPC&quot;)) pt4 En la gráfica podemos visualizar que la línea negra (datos reales) es bastante estable y se mantiene en valores bajos, mientras que la línea roja (predicciones) muestra mucha más variación y se aleja notablemente de los valores reales en muchos puntos. Se observan picos de predicción de más de 2000, cuando los valores reales no superan los 100 en la mayoría de las observaciones, esto sugiere que el modelo tiene alta varianza y probablemente está sobreajustando o captando ruido en lugar de patrones reales. Aunque los valores reales tienen ligeros picos y cambios, el modelo no los sigue, las predicciones muestran una dinámica completamente diferente, con cambios abruptos que no reflejan la tendencia real, en resumen, el modelo JORDAN no está prediciendo con precisión los valores reales, las predicciones están sobreestimando fuertemente en muchas observaciones. 7.3 Rendimiento Redes ELMAN y JORDAN 7.3.1 Rendimiento ELMAN # Calcular errores errores_elman &lt;- y_test - predtest1 # Métricas de evaluación mae &lt;- mae(y_test, predtest1) # Error absoluto medio rmse &lt;- rmse(y_test, predtest1) # Raíz del error cuadrático medio me &lt;- mean(errores_elman) # Error medio (ME) acf1 &lt;- acf(errores_elman, plot = FALSE)$acf[2] # ACF con rezago 1 # Mostrar resultados cat(&quot;MAE :&quot;, round(mae, 4), &quot;\\n&quot;) ## MAE : 16.7244 cat(&quot;RMSE :&quot;, round(rmse, 4), &quot;\\n&quot;) ## RMSE : 34.0165 cat(&quot;ME :&quot;, round(me, 4), &quot;\\n&quot;) ## ME : 0.2568 cat(&quot;ACF1 :&quot;, round(acf1, 4), &quot;\\n&quot;) ## ACF1 : -0.081 7.3.2 Rendimiento Jordan # Calcular errores errores_jordan &lt;- y_j_test - predtest2 # Métricas de evaluación mae &lt;- mae(y_j_test, predtest2) # Error absoluto medio rmse &lt;- rmse(y_j_test, predtest2) # Raíz del error cuadrático medio me &lt;- mean(errores_jordan) # Error medio (ME) acf1 &lt;- acf(errores_jordan, plot = FALSE)$acf[2] # ACF con rezago 1 # Mostrar resultados cat(&quot;MAE :&quot;, round(mae, 4), &quot;\\n&quot;) ## MAE : 172.283 cat(&quot;RMSE :&quot;, round(rmse, 4), &quot;\\n&quot;) ## RMSE : 407.6552 cat(&quot;ME :&quot;, round(me, 4), &quot;\\n&quot;) ## ME : -104.5171 cat(&quot;ACF1 :&quot;, round(acf1, 4), &quot;\\n&quot;) ## ACF1 : 0.1833 ** MAE (Mean Absolute Error)** ELMAN: 16.7244 JORDAN: 172.283 - ELMAN muestra un menor error absoluto medio. RMSE (Root Mean Square Error): ELMAN: 34.0165 JORDAN: 407,6752 - ELMAN tiene un RMSE menor, indicando menor variación entre predicciones y valores reales. ME (Mean Error) ELMAN:0.2568 JORDAN: -104.5171 - El modelo JORDAN tiene un error medio más bajo, lo que indica que sus predicciones están, en promedio más cerca de los valores reales. ACF1 (Autocorrelation of Residuals at Lag 1) ELMAN: -0.081 JORDAN: 0.1833 - ELMAN muestra menor autocorrelación en los residuos, indicando que los errores están menos correlacionados y probablemente son más independientes. Con base en la comparación de métricas de rendimiento, se concluye que el modelo ELMAN supera significativamente al modelo JORDAN en la predicción del ausentismo laboral. ELMAN presenta un MAE (16.72) y un RMSE (34.01) considerablemente menores que los del modelo JORDAN (MAE: 172.28, RMSE: 407.68), lo cual indica un mejor ajuste general y menor dispersión en los errores de predicción. Aunque JORDAN muestra un ME negativo (-104.51), que podría interpretarse como una menor sobreestimación en promedio, este valor tan alto sugiere una gran desviación sistemática, mientras que el ME de ELMAN (0.25) está cerca de cero, lo que implica predicciones más equilibradas. Además, el menor valor de autocorrelación de los residuos (ACF1) en ELMAN (-0.081) frente a JORDAN (0.1833) indica que los errores del modelo ELMAN están menos correlacionados en el tiempo, y por tanto, es menos probable que haya patrones no capturados en los residuos. El modelo ELMAN es superior al modelo JORDAN en la mayoria de las métricas analizadas, mostrando menor error y mejor ajuste a los datos reales. Por lo tanto, ELMAN arroja mejores resultado al presentar el mejor rendimiento de los 2 modelos, indicando predicciones más precisas y cercanas a los valores reales del ausentismo laboral. Las redes Elman son bastante útiles para modelar datos secuenciales, ya que pueden incorporar información del contexto previo para realizar mejores predicciones. 7.3.3 Conclusión La red neuronal JORDAN es un tipo de red recurrente que incorpora retroalimentación desde la capa de salida hacia una capa de contexto, lo que le permite mantener una memoria limitada del comportamiento pasado de la serie. Esta capacidad la hace especialmente valiosa en el análisis de series temporales, donde las observaciones anteriores influyen en las futuras. En este caso, en el modelo con los datos de entrenamiento, la red logra seguir la tendencia general en varios tramos, pero presenta picos artificiales extremos que no reflejan los datos reales, así mismo en los datos de prueba, las predicciones son mucho más erráticas y se alejan fuertemente de los valores reales. El modelo memoriza patrones del entrenamiento, pero no logra generalizar a nuevos datos. Esto es un claro indicio de overfitting. Por otro lado, en ambas gráficas, la red genera predicciones con valores extremadamente altos o bajos, incluso cuando los datos reales permanecen estables, este comportamiento sugiere que la red es demasiado sensible a pequeñas variaciones en la entrada o no está correctamente regularizada. La arquitectura o el preprocesamiento pueden estar mal ajustados. Es probable que se necesite una normalización más robusta, menos neuronas ocultas o aplicar regularización. Además, la variable de estudio tiene una dinámica relativamente estable con algunos picos, pero la red JORDAN no logra anticipar ni seguir coherentemente esos patrones. Esto puede deberse a una mala elección del número de rezagos (lags) o a que la red no está explotando bien la dependencia temporal. ELMAN ofrece mejores resultados al lograr mayor precisión y menor error en las predicciones. Este desempeño se debe a su capacidad para modelar relaciones secuenciales en los datos, haciendo uso de la retroalimentación interna que caracteriza a las redes recurrentes. Por lo tanto en este caso se consideraría una alternativa más robusta para tareas de pronóstico basadas en series temporales como el ausentismo laboral, aunque su predicción tampoco es muy precisa. Es importante considerar aspectos como el sobreajuste (overfitting) y el ajuste de hiperparámetros para asegurar que el modelo ELMAN no solo funcione bien sobre los datos de entrenamiento, sino que también generalice adecuadamente en nuevos datos. Para optimizar estos parámetros en ELMAN, es recomendable utilizar técnicas como búsqueda en rejilla (grid search) o búsqueda aleatoria (random search), idealmente combinadas con validación cruzada. Estas técnicas permiten explorar combinaciones y encontrar la configuración que proporciona el mejor rendimiento de generalización. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
